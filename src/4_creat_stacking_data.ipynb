{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26757,"status":"ok","timestamp":1657409899431,"user":{"displayName":"Hiroyuki Matsuda","userId":"09428550830703179646"},"user_tz":-540},"id":"74BBCdDq6sKr","outputId":"2aafce90-eb33-458f-b458-0891cb3f4c0c"},"outputs":[],"source":["!pip install transformers==4.20.1\n","!pip install seqeval==1.2.2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22271,"status":"ok","timestamp":1657409929548,"user":{"displayName":"Hiroyuki Matsuda","userId":"09428550830703179646"},"user_tz":-540},"id":"UH9z_6KkDI9h","outputId":"9ad1672b-4b5b-433e-da24-b233edfea942"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7OzPWRnDLO1"},"outputs":[],"source":["# 自身の環境のパスを指定\n","base_folder = \"drive/MyDrive/Colab\\ Notebooks/cpt-hanrei-1st-refactor/src\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279,"status":"ok","timestamp":1657409933177,"user":{"displayName":"Hiroyuki Matsuda","userId":"09428550830703179646"},"user_tz":-540},"id":"t8cCorK8G05w","outputId":"86184668-c6c4-4a5a-812c-46af71b86f5f"},"outputs":[],"source":["cd {base_folder}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mv2zWWPp61xS"},"outputs":[],"source":["import random\n","from sklearn.model_selection import KFold\n","from utils import load_pickle\n","from seqeval.metrics import classification_report,f1_score\n","from collections import Counter\n","import pandas as pd\n","import torch\n","import numpy as np\n","from utils import load_pickle, save\n","import os\n","pd.options.display.max_rows = 10000\n","\n","\n","\n","seed_map = {\n","    \"cl-wom\": 71,\n","    \"cl-charwom\": 271,\n","    \"cl\": 4306,\n","    \"cl-char\": 1545,\n","    \"NICT-100k\": 8155,\n","    \"NICT-32k\": 1250,\n","}\n","\n","\n","def correct_idx(input_tags, tokens):\n","    tags = [i for i in input_tags]\n","    valid_idxs = get_seq_idx(tags, True, return_type=\"idx\", flatten=False)\n","    for idxs in valid_idxs:\n","        string = \"\".join([tokens[i] for i in idxs])\n","        if len(string) <= 2:\n","            for i in idxs:\n","                tags[i] = \"O\"\n","    invalid_idxs = get_seq_idx(tags, False, return_type=\"idx\", flatten=True)\n","    for i in invalid_idxs:\n","        tags[i] = \"O\"\n","    return tags\n","\n","\n","def is_valid_seq(seq):\n","    return seq[0].split(\"-\")[0] == \"B\"\n","\n","\n","def get_seq_idx(tags, valid_flag=True, return_type=\"idx\", flatten=True):\n","    begin = False\n","    category = None\n","    all_idx_ls = []\n","    all_tag_ls = []\n","    idx_ls = []\n","    tag_ls = []\n","    for i, tag in enumerate(tags):\n","        if isinstance(tag, str):\n","            if tag != \"O\":\n","                pos = tag.split(\"-\")[0]\n","                category = tag.split(\"-\")[1]\n","                if not begin:\n","                    begin = True\n","                else:\n","                    if category != tag_ls[0].split(\"-\")[1]:\n","                        begin = False\n","                        if is_valid_seq(tag_ls) == valid_flag:\n","                            all_idx_ls.append(idx_ls)\n","                            all_tag_ls.append(tag_ls)\n","                        idx_ls = []\n","                        tag_ls = []\n","                idx_ls.append(i)\n","                tag_ls.append(tag)\n","            else:\n","                if begin:\n","                    begin = False\n","                    if is_valid_seq(tag_ls) == valid_flag:\n","                        all_idx_ls.append(idx_ls)\n","                        all_tag_ls.append(tag_ls)\n","                    idx_ls = []\n","                    tag_ls = []\n","    if return_type == \"idx\":\n","        result = all_idx_ls\n","    elif return_type == \"tag\":\n","        result = all_tag_ls\n","    if flatten:\n","        return [i for ls in result for i in ls]\n","    else:\n","        return result\n","\n","\n","def get_voted_result(result_list):\n","    voted_list = []\n","    for idx in range(len(result_list[0])):\n","        ls = [ls[idx] for ls in result_list]\n","        if len(set(ls)) == 1:\n","            voted_list.append(ls[0])\n","        else:\n","            counter = Counter(ls)\n","            voted_list.append(counter.most_common(1)[0][0])\n","    return voted_list\n","\n","seed_map = {\n","    \"cl-wom\": 71,\n","    \"cl-charwom\": 271,\n","    \"cl\": 4306,\n","    \"cl-char\": 1545,\n","    \"NICT-100k\": 8155,\n","    \"NICT-32k\": 1250,\n","}\n","tag2id = {'B-LOCATION': 7,\n","          'B-MISC': 9,\n","          'B-ORGFACPOS': 5,\n","          'B-PERSON': 3,\n","          'B-TIMEX': 1,\n","          'I-LOCATION': 8,\n","          'I-MISC': 10,\n","          'I-ORGFACPOS': 6,\n","          'I-PERSON': 4,\n","          'I-TIMEX': 2,\n","          'O': 0,\n","          'mask': -100}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PHXgE8Do6lAU"},"outputs":[],"source":["GINZA_DATA_PATH = f\"data/preprocessed/ginza_train_data.csv\"\n","MODEL_NAME_LIST = [\"cl-charwom\", \"cl-wom\", \"cl\", \"NICT-100k\", \"NICT-32k\", \"cl-char\"]\n","GINZA_TRAIN_DF = pd.read_csv(GINZA_DATA_PATH)\n","TEST_TOKENS = pd.read_csv(\"data/input/test_token.csv\").dropna().token.tolist()\n","FILE_IDS = GINZA_TRAIN_DF.file_id.unique()\n","\n","\n","class Result:\n","\n","    def __init__(self, trial_name, model_name,  fold, data_type):\n","        self.trail_name = trial_name\n","        self.model_name = model_name\n","        self.fold = fold\n","        self.data_type = data_type\n","\n","    @staticmethod\n","    def _extract_f1_from_report(report):\n","        return float(report.split()[report.split().index(\"micro\") + 4])\n","\n","    def retrieve_results(self, path=None):\n","        if not path:\n","            path = f\"save/train/{self.trail_name}_{self.model_name}/output/{self.data_type}_pred_{self.fold}.pk\"\n","        self.tags, self.labels, self.logits, report = load_pickle(path)\n","        self.f1 = self._extract_f1_from_report(report)\n","\n","\n","class ModelResult:\n","\n","    def __init__(self, trail_name, model_name,data_type):\n","        self.trial_name = trail_name\n","        self.model_name = model_name\n","        self.data_type = data_type\n","        self.tokens = self.get_tokens()\n","        self.fold_results = self.retrieve_results_for_each_fold()\n","        self.index = self.get_index()\n","        self.tags = self.get_tags()\n","        self.tags_corrected = correct_idx(self.tags, self.tokens)\n","        self.logits = self.get_logits()\n","\n","        if data_type==\"valid\":\n","            self.labels = self.get_labels()\n","            self.f1 = f1_score([self.labels], [self.tags])\n","            self.f1_corrected = f1_score([self.labels], [self.tags_corrected])\n","\n","    def get_tokens(self):\n","        if self.data_type == \"valid\":\n","            return GINZA_TRAIN_DF.token.tolist()\n","        return TEST_TOKENS\n","\n","    def retrieve_results_for_each_fold(self, folds=5):\n","        fold_results = []\n","        for fold in range(folds):\n","            result = Result(self.trial_name,\n","                            self.model_name,\n","                            fold,\n","                            self.data_type)\n","            result.retrieve_results()\n","            fold_results.append(result)\n","        return fold_results\n","\n","    def get_file_ids(self):\n","        file_ids = FILE_IDS.copy()\n","        seed = seed_map[self.model_name]\n","        random.Random(seed).shuffle(file_ids)\n","        return file_ids\n","\n","    def get_index(self):\n","        file_ids = self.get_file_ids()\n","        df_list = []\n","        for _, valid_idx in KFold(n_splits=5).split(file_ids):\n","            valid_file_ids = file_ids[valid_idx]\n","            for ids in valid_file_ids:\n","                df_list.append(GINZA_TRAIN_DF[GINZA_TRAIN_DF.file_id == ids])\n","        concated = pd.concat(df_list)\n","        index = concated.index\n","        return index\n","\n","    def get_from_all_fold(self, attr):\n","        item_list = []\n","        for fold in range(5):\n","            result = self.fold_results[fold]\n","            item = getattr(result, attr)\n","            if self.data_type == \"valid\":\n","                item_list.extend(item)\n","            else:\n","                item_list.append(item)\n","        return item_list\n","\n","    def get_tags(self):\n","        tags = self.get_from_all_fold(\"tags\")\n","        if self.data_type==\"valid\":\n","            return self.sort_according_idx(tags)\n","        else:\n","            return get_voted_result(tags)\n","\n","    def get_labels(self):\n","        labels = self.get_from_all_fold(\"labels\")\n","        return self.sort_according_idx(labels)\n","    \n","    def get_logits(self):\n","        logits = self.get_from_all_fold(\"logits\")\n","        logits = self.sort_according_idx(logits)\n","        return  torch.stack(logits, 0)\n","    \n","    def sort_according_idx(self, X):\n","        return [x for _,x in sorted(zip(self.index,X))]\n","\n","\n","class TrailResult:\n","\n","    def __init__(self, trail_name, data_type):\n","        self.trail_name = trail_name\n","        self.data_type = data_type\n","        self.tokens = self.get_tokens()\n","\n","        print(\"loding result files\")\n","        self.model_result_dict = {\n","            model_name: ModelResult(trail_name,model_name,data_type)\n","            for model_name in MODEL_NAME_LIST\n","        }\n","        self.tag_list = [\n","            model_result.tags for model_result in self.model_result_dict.values()\n","        ]\n","        self.tag_list_corrected = [\n","            model_result.tags_corrected for model_result in self.model_result_dict.values()\n","        ]\n","\n","    def generate_voted_result(self, tag_list, correct=False):\n","        voted = get_voted_result(tag_list)\n","        if correct:\n","            voted = correct_idx(voted, self.tokens)\n","        return voted\n","\n","    def get_tokens(self):\n","        if self.data_type == \"valid\":\n","            return GINZA_TRAIN_DF.token.tolist()\n","        return TEST_TOKENS\n","\n","    def generate_voted(self):\n","        print(\"generating voted result\")\n","        self.voted = self.generate_voted_result(self.tag_list)\n","        self.voted_before_corrected = self.generate_voted_result(self.tag_list, correct=True)\n","        self.voted_after_corrected = self.generate_voted_result(self.tag_list_corrected, correct=True)\n","\n","    def generate_report(self):\n","        label_list = GINZA_TRAIN_DF.tag.tolist()\n","        print(\"generating report\")\n","        self.f1_report_orig = \\\n","            classification_report([label_list], [self.voted], digits=4)\n","        self.f1_report_correct = \\\n","            classification_report([label_list], [self.voted_before_corrected], digits=4)\n","        self.f1_report_vote_after_correct = \\\n","            classification_report([label_list], [self.voted_after_corrected], digits=4)\n","\n","    def print_all(self):\n","        print(\"#\"*50)\n","        print(\"f1_orig\".ljust(50, '-'))\n","        for model, result in self.model_result_dict.items():\n","            print(model, round(result.f1, 4))\n","        print(\"f1_dict_corrected\".ljust(50, '-'))\n","        for model, result in self.model_result_dict.items():\n","            print(model, round(result.f1_corrected, 4))\n","        print(\"f1_report_orig\".ljust(50, '-'))\n","        print(self.f1_report_orig)\n","        print(\"f1_report_correct\".ljust(50, '-'))\n","        print(self.f1_report_correct)\n","        print(\"f1_report_vote_after_correct\".ljust(50, '-'))\n","        print(self.f1_report_vote_after_correct)\n","        print(\"#\" * 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":178740,"status":"ok","timestamp":1657410126440,"user":{"displayName":"Hiroyuki Matsuda","userId":"09428550830703179646"},"user_tz":-540},"id":"MHh1A0YlEVac","outputId":"20b47562-ad21-4db8-aaea-c61866eaf3ee"},"outputs":[],"source":["result = TrailResult(\"seed_data_for_each_model\", \"valid\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3QkA2QPyGnmA"},"outputs":[],"source":["logits_list = [result.model_result_dict[model].logits for model in MODEL_NAME_LIST]\n","logits = torch.cat(logits_list,axis=-1)\n","labels = pd.Series(result.model_result_dict[MODEL_NAME_LIST[0]].labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9V5XKTir7MdQ"},"outputs":[],"source":["from sklearn.model_selection import KFold\n","from tqdm.notebook import tqdm\n","\n","file_ids = GINZA_TRAIN_DF.file_id.unique()\n","seed = 4306\n","random.Random(seed).shuffle(file_ids)\n","\n","for fold, (train_idx, valid_idx) in enumerate(KFold(n_splits=5).split(file_ids)):\n","    train_file_ids = file_ids[train_idx]\n","    valid_file_ids = file_ids[valid_idx]\n","    file_id = train_file_ids[0]\n","    train_data_list = []\n","    valid_data_list = []\n","    for file_id in train_file_ids:\n","        single_data = {}\n","        sub_df = GINZA_TRAIN_DF[GINZA_TRAIN_DF.file_id == file_id]\n","        index = sub_df.index.tolist()\n","        single_data[\"logits\"]  = logits[index]\n","        single_data[\"tokens\"] = sub_df.token.tolist()\n","        single_data[\"labels\"]= [tag2id[tag] for tag in labels[index]]\n","        train_data_list.append(single_data)\n","    path = f\"data/preprocessed/train_stacking_data_seed_{seed}_fold_{fold}.pk\"\n","    save(train_data_list, path)\n","    for file_id in valid_file_ids:\n","        single_data = {}\n","        sub_df = GINZA_TRAIN_DF[GINZA_TRAIN_DF.file_id == file_id]\n","        index = sub_df.index.tolist()\n","        single_data[\"logits\"]  = logits[index]\n","        single_data[\"tokens\"] = sub_df.token.tolist()\n","        single_data[\"labels\"]= [tag2id[tag] for tag in labels[index]]\n","        valid_data_list.append(single_data)\n","    path = f\"data/preprocessed/valid_stacking_data_seed_{seed}_fold_{fold}.pk\"\n","    save(valid_data_list, path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BrTzCG58TcU"},"outputs":[],"source":["test_df = pd.read_csv(\"data/input/test_token.csv\").dropna().reset_index(drop=True)\n","file_ids = test_df.file_id.unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36156,"status":"ok","timestamp":1657410793264,"user":{"displayName":"Hiroyuki Matsuda","userId":"09428550830703179646"},"user_tz":-540},"id":"EfxeXF9uBgW4","outputId":"576140a7-e406-42d4-c6d7-f9cfa8499afc"},"outputs":[],"source":["result = TrailResult(\"seed_data_for_each_model\", \"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0N5AHgo_8fTt"},"outputs":[],"source":["test_logits = []\n","for model in MODEL_NAME_LIST:\n","    logits_list = [result.model_result_dict[model].fold_results[fold].logits\n","                for fold in range(5)\n","                ]\n","    logits = sum(logits_list)/len(logits_list)\n","    test_logits.append(logits)\n","logits = torch.cat(test_logits,axis=-1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GzDc-AMu8h5H"},"outputs":[],"source":["test_data_list = []\n","\n","for file_id in file_ids:\n","    sub_df = test_df[test_df.file_id == file_id]\n","    idx = sub_df.index.tolist()\n","    \n","    dic = {\"logits\":logits[idx],\n","           \"tokens\":sub_df.token.tolist()\n","           }\n","    test_data_list.append(dic)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"emlAK6MO8le9"},"outputs":[],"source":["path = f\"data/preprocessed/test_stacking_data_new_aug.pk\"\n","save(test_data_list, path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_iUYItNIFimW"},"outputs":[],"source":["for fold in range(5):\n","    test_logits = []\n","    for model in MODEL_NAME_LIST:\n","        logits_list = result.model_result_dict[model].fold_results[fold].logits\n","        test_logits.append(logits_list)\n","    logits = torch.cat(test_logits,axis=-1)\n","    test_data_list = []\n","    for file_id in file_ids:\n","        sub_df = test_df[test_df.file_id == file_id]\n","        idx = sub_df.index.tolist()\n","        \n","        dic = {\"logits\":logits[idx],\n","            \"tokens\":sub_df.token.tolist()\n","            }\n","        test_data_list.append(dic)\n","    path = f\"data/preprocessed/test_stacking_data_{fold}_new_aug.pk\"\n","    save(test_data_list, path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SQJACFcuRBM4"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"4_creat_stacking_data.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
